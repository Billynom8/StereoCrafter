{
  "input_folder": "Select the directory containing your input MP4 videos. The script expects '_splatted4' for quad inputs (Original, Depth, Mask, Warped) or '_splatted2' for dual inputs (Mask, Warped).",
  "output_folder": "Choose the directory where the processed (inpainted) videos will be saved. Output will be Side-by-Side (original | inpainted) for quad inputs, or only the inpainted right eye for dual inputs.",
  "num_inference_steps": "Number of denoising steps for the video generation process. Higher values generally lead to better quality but increase processing time. Default:5 ",
	"output_crf": "Constant Rate Factor for video encoding (lower is higher quality). Adjust based on codec (H.264/H.265).",
  "tile_num": "Number of spatial tiles (e.g., 2 means 2x2 grid) to split each video frame into. Useful for processing high-resolution videos with limited GPU memory. Set to 1 to disable tiling. Default:1",
  "frames_chunk": "The number of frames processed together in a single temporal batch. Adjust based on your GPU memory. Larger chunks can be faster but require more VRAM. Default:23",
  "frame_overlap": "The number of frames that temporally overlap between consecutive processing chunks. These overlapping frames from the previous generated output and original input are smoothly blended to condition the start of the current chunk, reducing visual glitches. Default:3",
  "original_input_blend_strength": "Controls how much the original warped input (1.0) versus the previous generated inpainted frame (0.0) influences the blend during temporal overlap. higher for less hallucination but less consistency Default:0 = Off",
  "offload_type": "Determines how parts of the model are moved to CPU memory to reduce GPU VRAM usage. 'model' offloads entire components, 'sequential' offloads layers one by one, 'none' keeps everything on GPU.",
  "process_length": "Number of frames to process for each video. Enter -1 to process all frames, or a positive integer to limit the processing to the first N frames. Useful for quick testing.",
  "latent_blend_strength": "Strength of latent-space crossfade applied on the first overlap frames. Smoothly blends denoised latents from the previous chunk with the current chunk to reduce seams. Range: 0.0–1.0. Default:0.8",	
	"enable_post_inpainting_blend": "Toggle the final post-inpainting blending step and enable/disable its parameters.",
	"enable_color_transfer": "If enabled, the color palette and statistics of the inpainted output will be adjusted to match the original left eye view, improving visual consistency. Now also works in dual-splatted inputs.",
	"mask_initial_threshold": "Sets a mid value to turn a grayscale image into black and white, separating light and dark areas. (0 to 1). Set to 0 to disable.",
	"mask_morph_kernel_size": "Kernel size for morphological closing: Defines the size of the shape used to fill small holes and smooth edges in an image during the closing process (e.g., 3, 5). Set to 0 to disable.",
	"mask_dilate_kernel_size": "Sets the size of the shape used to expand white areas in a mask, making objects larger and filling small gaps during dilation  (e.g., 7, 15). Set to 0 to disable.",
	"mask_blur_kernel_size": "Kernel size for Gaussian blur (e.g., 15, 25). Sigma is derived automatically. Set to 0 to disable.",
  "enable_motion_comp": "Enable lightweight optical-flow warping of the previous chunk toward the current frames before crossfading the first overlap frames. Helps reduce double-image ghosting at seams. Default:true",
  "ema_radius": "Number of frames after each seam to smooth using an exponential moving average. Use small values (1–2) for subtle polish. 0 disables. Default:2",
  "ema_alpha": "Smoothing strength for the EMA seam polish (0.0–1.0). Lower = gentler and preserves the current frame more; higher follows the preceding frame more. Default:0.25",
	"general_help": "This is a GUI for StereoCrafter, a Stable Video Diffusion Inpainting Pipeline. It takes warped videos (e.g., from depth_splatting_gui.py) and fills in occluded areas. Input videos are expected to be either 'quad-splatted' (original, depth, mask, warped) or 'dual-splatted' (mask, warped). Outputs are either Side-by-Side (original | inpainted) or just the inpainted right eye, respectively. Adjust 'Tile Number' and 'Frames Chunk' if you encounter out-of-memory errors. 'Frame Overlap' helps smooth transitions between processed chunks. Use 'Original Input Bias' to balance consistency with the generated past vs. adherence to the original video source."
}
